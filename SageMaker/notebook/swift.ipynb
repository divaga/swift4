{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Identification with Amazon SageMaker Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Train a document identification model using SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data folder structure\n",
    "You need to prepare training data in this following folder structure:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ROOT_FOLDER\n",
    "    \\_ CLASS_1\n",
    "        \\_ file_1\n",
    "        \\_ file_2\n",
    "        \\_ file_n\n",
    "    \\_ CLASS_2\n",
    "    \\_ CLASS_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a zip file for your root folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute this only once\n",
    "!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "import cv2\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "bucket=sess.default_bucket()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you have same current directory with your notebook\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change this!\n",
    "change this based on your preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'swift' # Put your data source folder prefix here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip and process your training data\n",
    "DO THIS FIRST: upload your zip file to same directory with your notebook file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove existing folder, in this example SWIFT is our root folder\n",
    "!rm -R SWIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip your zip training data file\n",
    "!unzip swift.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete existing processing folder\n",
    "This following cell will delete previous processing folder. You don't need to execute this if you are using this notebook for first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rm -R document_dataset\n",
    "rm -R document_dataset_augmented\n",
    "rm -R document_dataset_augmented_val\n",
    "rm -R data_recordio\n",
    "rm document-train.lst\n",
    "rm document-val.lst\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHANGE THIS!\n",
    "Change these values based on your class name and your root folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS BASED ON YOUR CLASSES/FOLDER NAME IN ALFABHETICAL ORDER\n",
    "document_type = ['ID_CITIZEN_ID', 'ID_DRIVING_LICENSE', 'ID_PASSPORT','MY_CITIZEN_ID', 'MY_DRIVING_LICENSE', 'MY_PASSPORT','PH_CITIZEN_ID', 'PH_DRIVING_LICENSE', 'PH_PASSPORT','TH_CITIZEN_ID', 'TH_DRIVING_LICENSE', 'TH_PASSPORT','VN_CITIZEN_ID', 'VN_DRIVING_LICENSE', 'VN_PASSPORT']\n",
    "# resized locations\n",
    "inputBasePath = './SWIFT/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create temporary dataset for image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$inputBasePath\"\n",
    "\n",
    "mkdir -p document_dataset\n",
    "for i in \"$1\"/*; do\n",
    "    c=`basename $i`\n",
    "    mkdir -p document_dataset/$c\n",
    "    for j in `ls $i/*.jpg | shuf | head -n 15`; do        \n",
    "        mv $j document_dataset/$c/\n",
    "    done\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images augmentation\n",
    "We will perform images augmentation to enrich our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from PIL import Image, ImageEnhance\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "import random\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation functions\n",
    "\n",
    "def sharpen(img, factor):\n",
    "    enhancer_sharpness = ImageEnhance.Sharpness(img)\n",
    "    return enhancer_sharpness.enhance(factor)\n",
    "\n",
    "def contrast(img, factor):\n",
    "    enhancer_contrast = ImageEnhance.Contrast(img)\n",
    "    return enhancer_contrast.enhance(factor)\n",
    "\n",
    "def rotate(img, degrees):\n",
    "    return img.rotate(degrees)\n",
    "\n",
    "def save(img, path):\n",
    "    return img.save(path, \"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new locations\n",
    "inputBasePath = './document_dataset/'\n",
    "outputBasePath = './document_dataset_augmented/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "rotations = [0,90,270]\n",
    "randContrastMin, randContrastMax = (0.8, 1.2)\n",
    "randSharpenMin, randSharpenMax  = (0.8, 1.2)\n",
    "multiplier = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "for f in document_type:\n",
    "    plist = Path(inputBasePath + f + '/').glob('*.jpg')\n",
    "   \n",
    "    outpath = outputBasePath + f + '/' \n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "    \n",
    "    for path in plist:\n",
    "        i = Image.open( path )\n",
    "\n",
    "        for r in rotations:\n",
    "            \n",
    "            for m in range(multiplier):\n",
    "                \n",
    "                randContrast = random.uniform(randContrastMin, randContrastMax)\n",
    "                randSharpen = random.uniform(randSharpenMin, randSharpenMax)\n",
    "\n",
    "                i = rotate(i, r)\n",
    "                i = contrast(i, randContrast)\n",
    "                i = sharpen(i, randSharpen)\n",
    "                \n",
    "                save(i, outpath + str(uuid.uuid4()) + '.jpg') \n",
    "                print('.', end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new locations, please change inputBasePath to your root folder\n",
    "inputBasePath = './SWIFT/'\n",
    "outputBasePath = './document_dataset_augmented_val/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "rotations = [0,90,270]\n",
    "randContrastMin, randContrastMax = (0.8, 1.2)\n",
    "randSharpenMin, randSharpenMax  = (0.8, 1.2)\n",
    "multiplier = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "for f in document_type:\n",
    "    plist = Path(inputBasePath + f + '/').glob('*.jpg')\n",
    "\n",
    "    outpath = outputBasePath + f + '/' \n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "    \n",
    "    for path in plist:\n",
    "        i = Image.open( path )\n",
    "\n",
    "        for r in rotations:\n",
    "            \n",
    "            for m in range(multiplier):\n",
    "                \n",
    "                randContrast = random.uniform(randContrastMin, randContrastMax)\n",
    "                randSharpen = random.uniform(randSharpenMin, randSharpenMax)\n",
    "                i = rotate(i, r)\n",
    "                i = contrast(i, randContrast)\n",
    "                i = sharpen(i, randSharpen)\n",
    "                \n",
    "                save(i, outpath + str(uuid.uuid4()) + '.jpg') \n",
    "                print('.', end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download im2rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "        \n",
    "# Tool for creating lst file\n",
    "download('https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lst file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python im2rec.py --list --recursive document-train document_dataset_augmented/\n",
    "python im2rec.py --list --recursive document-val document_dataset_augmented_val/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of training samples\n",
    "training_count = len(open('document-train.lst').readlines())\n",
    "print(training_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert to RecordIO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pathlib\n",
    "\n",
    "recordio_dir = pathlib.Path('./data_recordio')\n",
    "recordio_dir.mkdir(exist_ok=True)\n",
    "shutil.copy('document-train.lst', 'data_recordio/');\n",
    "shutil.copy('document-val.lst', 'data_recordio/');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python im2rec.py --resize 224 --quality 90 --num-thread 16 data_recordio/document-train document_dataset_augmented/\n",
    "!python im2rec.py --resize 224 --quality 90 --num-thread 16 data_recordio/document-val document_dataset_augmented_val/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to S3\n",
    "Upload the data to the S3 bucket. We do this in multiple channels. Channels are simply directories in the bucket that differentiate between training and validation data.\n",
    "Create these following folders in S3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_uploader = sagemaker.s3.S3Uploader()\n",
    "\n",
    "data_path = recordio_dir / 'document-train.rec'\n",
    "\n",
    "data_s3_uri = s3_uploader.upload(\n",
    "    local_path=data_path.as_posix(), \n",
    "    desired_s3_uri=f's3://{bucket}/{prefix}/data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = recordio_dir / 'document-val.rec'\n",
    "\n",
    "data_s3_uri = s3_uploader.upload(\n",
    "    local_path=data_path.as_posix(), \n",
    "    desired_s3_uri=f's3://{bucket}/{prefix}/data/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput( \n",
    "    s3_data=f's3://{bucket}/{prefix}/data/train',\n",
    "    content_type='application/x-recordio',\n",
    "    s3_data_type='S3Prefix',\n",
    "    input_mode='Pipe')\n",
    "\n",
    "val_data = sagemaker.inputs.TrainingInput( \n",
    "    s3_data=f's3://{bucket}/{prefix}/data/val',\n",
    "    content_type='application/x-recordio',\n",
    "    s3_data_type='S3Prefix',\n",
    "    input_mode='Pipe')\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': val_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Image Classification Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(document_type)\n",
    "num_training_samples = training_count\n",
    "\n",
    "training_image = sagemaker.image_uris.retrieve('image-classification', sagemaker.Session().boto_region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the algorithm's hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'num_layers': 18,\n",
    "    'use_pretrained_model': 1,\n",
    "    'augmentation_type': 'crop_color_transform',\n",
    "    'image_shape': \"3,224,224\",\n",
    "    'num_classes': num_classes,\n",
    "    'num_training_samples': num_training_samples,\n",
    "    'mini_batch_size': 29,\n",
    "    'epochs': 30,\n",
    "    'learning_rate': 0.000054,\n",
    "    'precision_dtype': 'float32',\n",
    "    'optimizer':'rmsprop'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_config = {\n",
    "    'hyperparameters': hyperparameters,\n",
    "    'image_uri': training_image,\n",
    "    'role': sagemaker.get_execution_role(), \n",
    "    'instance_count': 1, \n",
    "    'instance_type': 'ml.p3.8xlarge',\n",
    "    'volume_size': 100,\n",
    "    'max_run': 360000,\n",
    "    'output_path': f's3://{bucket}/{prefix}/data/output'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = sagemaker.estimator.Estimator(**algo_config)\n",
    "algorithm.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "imageclassification = sagemaker.estimator.Estimator(training_image, \n",
    "                                                    role, \n",
    "                                                    instance_count=1,\n",
    "                                                    instance_type='ml.p3.8xlarge',\n",
    "                                                    output_path=f's3://{bucket}/{prefix}/data/output', \n",
    "                                                    sagemaker_session=sess)\n",
    "\n",
    "imageclassification.set_hyperparameters(num_layers=18, \n",
    "                                        image_shape='3,224,224',\n",
    "                                        num_classes=num_classes,\n",
    "                                        epochs=30, \n",
    "                                        top_k='2',\n",
    "                                        num_training_samples=num_training_samples,\n",
    "                                        precision_dtype='float32',\n",
    "                                        augmentation_type='crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime \n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "tuning_job_name = \"document-tuning-job-{}\".format(strftime(\"%d-%H-%M-%S\", gmtime()))\n",
    "\n",
    "hyperparameter_ranges = {'learning_rate': ContinuousParameter(0.00001, 1.0),\n",
    "                         'mini_batch_size': IntegerParameter(16, 64),\n",
    "                         'optimizer': CategoricalParameter(['sgd', 'adam', 'rmsprop', 'nag'])}\n",
    "\n",
    "objective_metric_name = 'validation:accuracy'\n",
    "\n",
    "tuner = HyperparameterTuner(imageclassification, \n",
    "                            objective_metric_name, \n",
    "                            hyperparameter_ranges,\n",
    "                            objective_type='Maximize', \n",
    "                            max_jobs=20, \n",
    "                            max_parallel_jobs=2,\n",
    "                            early_stopping_type='Auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit({'train': train_data, 'validation': val_data}, \n",
    "          job_name=tuning_job_name, include_cls_metadata=False)\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_metrics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "tuner_metrics.dataframe().sort_values(['FinalObjectiveValue'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = tuner_metrics.dataframe()['TrainingElapsedTimeSeconds'].sum() / 3600\n",
    "print(\"The total training time is {:.2f} hours\".format(total_time))\n",
    "tuner_metrics.dataframe()['TrainingJobStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "***\n",
    "\n",
    "A trained model does nothing on its own. We now want to use the model to perform inference. For this example, that means predicting the class of the image. You can deploy the created model by using the deploy method in the estimator.\n",
    "\n",
    "### Please choose model from initial training job or hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deploy best model from hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_classifier = tuner.deploy(initial_instance_count = 1,\n",
    "                                          instance_type = 'ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deploy from initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_classifier = algorithm.deploy(initial_instance_count = 1,\n",
    "                                          instance_type = 'ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Test\n",
    "You can upload your test image data in same directory with this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "    \n",
    "import cv2\n",
    "\n",
    "file_name = 'test2.jpg'  # your test image\n",
    "\n",
    "#resize\n",
    "im = cv2.imread(file_name)\n",
    "im = cv2.resize(im, (600, 400))\n",
    "cv2.imwrite(file_name, im)\n",
    "\n",
    "\n",
    "# display test image\n",
    "from IPython.display import Image, display\n",
    "img = Image(file_name) \n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(file_name, 'rb') as image:\n",
    "    f = image.read()\n",
    "    b = bytearray(f)\n",
    "\n",
    "results = ic_classifier.predict(b, initial_args={'ContentType': 'image/jpeg'})\n",
    "prob = json.loads(results)\n",
    "classes = document_type\n",
    "for idx, val in enumerate(classes):\n",
    "    print('%s:%f '%(classes[idx], prob[idx]), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS BASED ON TRAINING DATA INDEX\n",
    "#print(result)\n",
    "import numpy as np\n",
    "\n",
    "index = np.argmax(prob)\n",
    "print(\"Result: label - \" + document_type[index] + \", probability - \" + str(prob[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference using Sagemaker Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "    \n",
    "import cv2\n",
    "\n",
    "\n",
    "file_name = 'ktp2.jpg' # your test image\n",
    "\n",
    "\n",
    "#resize\n",
    "im = cv2.imread(file_name)\n",
    "im = cv2.resize(im, (600, 400))\n",
    "cv2.imwrite(file_name, im)\n",
    "\n",
    "\n",
    "# display test image\n",
    "from IPython.display import Image, display\n",
    "img = Image(file_name) \n",
    "display(img)\n",
    "\n",
    "with open(file_name, 'rb') as image:\n",
    "    f = image.read()\n",
    "    b = bytearray(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "runtime_sm_client = boto3.client(service_name='sagemaker-runtime')\n",
    "\n",
    "\n",
    "ENDPOINT_NAME = 'document-tuning-job-xxxxxxx' # CHANGE THIS !!\n",
    "start_time = time.time()\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=ENDPOINT_NAME,\n",
    "        ContentType='image/jpeg',\n",
    "        Body=b)\n",
    "\n",
    "prob = json.loads(response['Body'].read())\n",
    "duration = time.time() - start_time\n",
    "classes = document_type\n",
    "\n",
    "index = np.argmax(prob)\n",
    "print(\"Result: label - \" + document_type[index] + \", probability - \" + str(prob[index]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_classifier.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/mxnet-1.8-cpu-py37-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
